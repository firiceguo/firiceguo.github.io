---
layout: post
title: "机器学习 —— 评估方法"
date: 2016-08-24 15:33
tags: MachineLearning
categories: MachineLearning
thumbnail:  books
description: 一些设置训练集和数据集的方法
---

## 评估方法

包含m个样例的数据集: D = {(x1, y1), (x2, y2), ... , (xm, ym)}

训练集: T

数据集: S


## *留出法*

直接将数据集分成训练集和数据集

常见的方法是对大约**2/3~4/5**的样本进行训练

>优点：简洁方便

>缺点：S过大，虽能包含大部分数据，但测试精度不高；S过小，虽测试精度提高，但和D相差过大，降低评估系统的“保真性”（fidelity）


## *交叉验证法（“k折交叉验证” k-fold cross validation）*

将数据集分成k份，每一份都分为训练集和测试集两部分，将测试结果平均得到最终结果

k常取5，10，20

为了避免由于不同的划分产生的差别，通常随机使用不同的划分，并且重复p次，最终的结果是**p次k折交叉验证法**的均值


## *变形：留一法 (eave-One-Out, LOO)*

若D中有m个样本，当k=m时，每个子集包含一个样本

>优点：结果比较准确

>缺点：数据集太大时开销难以承受

>以上的方法都会引入一些因训练样本规模不同而导致的估计偏差
{: .note}


## *自助法 bootstrapping*

每次随机从D中挑出一个样本复制到D0中，重复m次，则在m次采样中始终不被采样到的概率取极限为：

$$ \lim_{m\to\infty}(1-\frac1m)^n \to \frac1e\approx 0.368 $$

即通过自助采样，初始数据集中有36.8%的数据没有出现在$$D_0$$中，我们可以将$$D_0$$作为训练集，$$D\D_0$$作为测试集

> 优点：在数据集较小、难以有效划分训练/测试集时很有用，对于集成学习等方法有很大的好处

> 缺点：改变了初始数据集的分布，会引入估计偏差
