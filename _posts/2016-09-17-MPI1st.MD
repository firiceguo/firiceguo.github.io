---
layout: post
title: "MPI programming -- Hello world!"
date: 2016-09-17 22:43
tags: ParallelProgramming
categories: ParallelProgramming
thumbnail:  book
description: The 1st demo with discription using MPI
---

## 0. 写在前面

上节课下课之后教授说，下节课开始正规地学习并行编程的代码。我心想，太好了，终于在经过两周的基本概念之后要上干货了。

然而。。。然而。。。我把下午的课当成晚上上了，干净利落地错过了本周最期待的课，只能自己啃书、课件和文档了:sob::sob::sob:

## 1. MPI 简介 && 准备工作

MPI 的全称是 Message-Passing Interface，它不是一门编程语言，是一个能被C/C++/Fortran调用的函数库。

我用的是[Open MPI](https://www.open-mpi.org/)（它的文档也在[这里](https://www.open-mpi.org/doc/v1.10/)），通过[Cygwin](https://www.cygwin.com/)安装使用。

Cygwin是一个在Windows中模拟Linux环境的东西，打开它好像打开了Linux命令行，真的很爽啊哈哈哈哈。它自带的`Open MPI`版本是`1.10.4`。


## 2. Hello World！

经典的用C语言写的Hello World程序如下（吐槽一下，老写Python好久不写C，常常忘了句尾还有分号:joy:）：

{% highlight C %}
#include <stdio.h>
int main(void) {
	printf("Hello world!\n");
	return(0);
}
{% endhighlight C %}

下面是加上MPI的程序：

{% highlight C %}
#include <stdio.h>
#include <string.h>  /* For strlen             */
#include <mpi.h>     /* For MPI functions, etc */ 

const int MAX_STRING = 100;

int main(void) {
   char       greeting[MAX_STRING];  /* String storing message */
   int        comm_sz;               /* Number of processes    */
   int        my_rank;               /* My process rank        */

   /* Start up MPI */
   MPI_Init(NULL, NULL); 

   /* Get the number of processes */
   MPI_Comm_size(MPI_COMM_WORLD, &comm_sz); 

   /* Get my rank among all the processes */
   MPI_Comm_rank(MPI_COMM_WORLD, &my_rank); 

   if (my_rank != 0) { 
      /* Create message */
      sprintf(greeting, "Greetings from process %d of %d!", 
            my_rank, comm_sz);
      /* Send message to process 0 */
      MPI_Send(greeting, strlen(greeting)+1, MPI_CHAR, 0, 0,
            MPI_COMM_WORLD); 
   } else {  
      /* Print my message */
      printf("Greetings from process %d of %d!\n", my_rank, comm_sz);
      for (int q = 1; q < comm_sz; q++) {
         /* Receive message from process q */
         MPI_Recv(greeting, MAX_STRING, MPI_CHAR, q,
            0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
         /* Print message from process q */
         printf("%s\n", greeting);
      } 
   }

   /* Shut down MPI */
   MPI_Finalize(); 

   return 0;
}
{% endhighlight C %}

这多的东西够多的，一个一个来吧：

### 1. `MPI_Init(NULL, NULL)`

这个函数是初始化MPI系统用的，比如初始化系统存储中的消息缓冲区等等。这个MPI函数必须是第一个运行的，只有先运行了它之后别的函数才能工作。下面是它的函数声明：

{% highlight C %}
int MPI_Init(
	int∗ 	argc_p /∗ in/out ∗/,
	char∗∗∗ argv_p /∗ in/out ∗/);
{% endhighlight C %}

它有两个参数`argc_p`和`argv_p`，分别是两个指向`main`、`argc`和`argv`的指针。当我们不用这两个参数的时候，可以把它设为`NULL`，就像上面那个程序那样。`MPI_Init`通常会返回一个值作为错误代码，在很多MPI函数中也是这样的，但是在大多数情况下可以忽略。

我查了一下手册，C、C++和Fortran返回的东西都不一样，如果要用的时候还要注意。

### 2. `MPI_Finalize()`

这个函数的作用刚好和上面那个相反，MPI_Init的作用是初始化，那么这个的作用就是告诉程序我们的任务完成了，它会销毁所有的MPI状态。

> 我又翻了下手册，其实有很多内容，但是想一想一开始还是先会用吧，要不然会陷入对文档的深度优先遍历出不来了的状态。

### 3. `MPI_COMM_WORLD`

是一个通信器(Communicator)，通信器是一组能互相发送信息的过程(processes)。每当MPI_Init运行的时候都会建立一个通信器包括所有的已建立的过程，这个通信器就叫做`MPI_COMM_WORLD`。

{% highlight C %}
   /* Get the number of processes */
   MPI_Comm_size(MPI_COMM_WORLD, &comm_sz); 

   /* Get my rank among all the processes */
   MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);
{% endhighlight C %}

这两句分别指定了通信器中的过程数`&comm_sz`和每个过程在通信器中的等级`&my_rank`。

下面的分别是发送信号`MPI_Send`和接收信号`MPI_Recv`的过程。如果`my_rank`也就是每个过程的等级不为0，那么就是发信器，如果等级为0，那么就是接收器。

> 这是一个SPMD(Single-Program Multiple-Data)程序。

### 4. `MPI_Send`

直接上函数的声明：

{% highlight C %}
int MPI_Send(const void *buf, int count, MPI_Datatype datatype,
			 int dest, int tag, MPI_Comm comm)
{% endhighlight C %}

其中各个参数的说明：


Parameters | Description
--------   | ------------------------
buf        | Initial address of send buffer (choice).
--------   | ------------------------
count      | Number of elements send (nonnegative integer).
--------   | ------------------------
datatype   | Datatype of each send buffer element (handle).
--------   | ------------------------
dest       | Rank of destination (integer).
--------   | ------------------------
tag        | Message tag (integer).
--------   | ------------------------
comm       | Communicator (handle).
--------   | ------------------------

前三个参数决定了发送信息的内容、大小和类型，后三个参数决定了信息的目的地。


### 5. `MPI_Recv`

函数声明：

{% highlight C %}
int MPI_Recv(void *buf, int count, MPI_Datatype datatype,
    		 int source, int tag, MPI_Comm comm, MPI_Status *status)
{% endhighlight C %}

参数说明：

Parameters | Description
--------   | ----------------------------
count      | Maximum number of elements to receive (integer).
--------   | ----------------------------
datatype   | Datatype of each receive buffer entry (handle).
--------   | ----------------------------
source     | Rank of source (integer).
--------   | ----------------------------
tag        | Message tag (integer).
--------   | ----------------------------
comm       | Communicator (handle).
--------   | ----------------------------



### 6. 信息传递

把两个函数声明放在一起看，假设等级为q的进程要发送信息给等级为r的进程：

{% highlight C %}
MPI_Send(send_buf_p, send_buf_sz, send_type, dest, send_tag,
send_comm);
MPI_Recv(recv_buf_p, recv_buf_sz, recv_type, src, recv_tag,
recv_comm, &status);
{% endhighlight C %}

那么接收到的结果是：

- recv_comm := send_comm
- recv_tag := send_tag
- dest := r
- src := q

这样看来，发送器会发送不知道什么鬼东西给接收器，但是接收器会根据自己能够接收的内容、大小和类型来过滤信息，把不需要的信息过滤掉。
