---
layout: post
title: "PyCUDA Adventure"
date: 2016-12-04 19:55
tags: ParallelProgramming
categories: ParallelProgramming
thumbnail:  cogs
comments: true
description: Some issuses during using PyCUDA
---

## 0. 从鄙视到屈服

一切都要从一年前开始。当时同学让我帮忙改一个 `OpenCL` 代码，我当时也什么都不会啊，但是凭着一股傻劲去看，发现看不懂。从此在内心里埋下了一个要写 GPU 代码的种子。所以这学期有一门并行编程的课，我没有经过思考和上课，直接选了这门课。

这门课是通过做独立 project 来评分的。上课的时候，老师推荐了很多可以把程序并行化的工具，比如  `MPI` 啊 `OpenMP` 啊，甚至可以用 Python 的 `threads` 来做，或者也可以用 `tensorflow`， `Hadoop` 或者 `Spark` 来做，我的另一门课做的就是分布式tensorflow。本来可以两门课综合起来的，做分布式tensorflow其实也可以交这门课的差。

但是，我的内心就是有一个要写GPU代码的“理想”，所以义无反顾地直接选了`CUDA`，完全不顾自己荒废三年的 `C/C++` 编程，从此入坑，为此买电脑的时候专门买了一个N卡的电脑（我承认有一部分原因是玩游戏啦哈哈）。

既然要写CUDA，就要用 `CUDA C` 写啊，这样才能不浪费好不容易节省出来的时间，但是我内心还有有一丝担忧，因此我在写 proplsal 的时候没说非要用 `CUDA C`，因为看到过 CUDA 能提供 Python 的 API， 为此还专门去查了下 `CUDA Python` 的评价，结果不出意外是很差的。大概就是因为 kernel 依然要用 `CUDA C` 写，所以 kernel 的执行时间是一样的，但是剩下的，由 Python 完成的任务，就非常慢了。

后来由于。。课。。业。。太。。重。。。拾起来我的 C 实在是没有时间了，所以我就选择用 `PyCUDA` 了。但其实 `PyCUDA` 更坑，网上问问题的少，说明也少，所以 debug 基本靠输出和手算（或者我没找到合适的工具？）。好在选的题不算太难，所以还算勉强完成任务。


## 1. `~/.bashrc`

由于我用的Linux Mint，有一些环境变量要自己设置，在此我把我的 `~/.bashrc` 文件后面加的部分粘上来以备以后用：

```bash
export GLPATH=/usr/lib
export LD_LIBRARY_PATH=/usr/local/cuda/lib
export PATH=$PATH:/usr/local/cuda/bin
export CUDA_ROOT=/usr/local/cuda-8.0
export PATH=$PATH:/usr/local/cuda-8.0/bin
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/lib
export CPATH=$CPATH:/usr/local/cuda-8.0/include
export CUDA_INC_DIR=/usr/local/cuda-8.0/bin:$CUDA_INC_DIR
```

## 2. 和 CUDA
 
由于 PyCUDA 的 Kernel 依然要用 CUDA C 来写，其实和 CUDA C 是差不多的，也要把数据从内存拷到显存里面之类的。

首先是 import CUDA 的库：

{% highlight python %}
import pycuda.driver as drv
from pycuda import compiler, autoinit
from pycuda.compiler import SourceModule
{% endhighlight python %}

其中 `pycuda.autoinit` 载入的时候，会自动初始化 CUDA 的运行环境，因为有一次，我把电源拔了，自动省电把我的N卡禁了，这一行就报错了。

还需要一个 `NumPy` 库：

{% highlight python %}
import numpy as np
{% endhighlight python %}

下面是一个把内存数据拷贝到显存的例子（我当时还看到一些别的方法，但是都报错，只有这一种是正常的）：

{% highlight python %}
pic_gpu = drv.mem_alloc(pic_s.nbytes)
drv.memcpy_htod(pic_gpu, pic_s)
{% endhighlight python %}

这里就是举个例子，就不把所有的变量粘过来了。

然后编译 kernel 函数

{% highlight python %}
mod = compiler.SourceModule(knl_template)
niv_conv = mod.get_function("niv_conv")
{% endhighlight python %}

其中 `knl_template` 是用 CUDA C 写的 kernel 函数，但是要用字符串传入，具体可以看我代码的例子。这一步之后，kernel 函数 `niv_conv` 就可以当函数使用了。

这里放一个简单的图像卷积的最简单的例子的 kernel 函数，字符串形式的哈哈：

{% highlight python %}
    knl_template = """
__global__ void niv_conv(
    float out[%(IMAGE_W)s * %(IMAGE_W)s],
    float kernel[%(KERNEL_R)s * %(KERNEL_R)s],
    float pic[%(IMAGE_W)s * %(IMAGE_W)s])
{
    int idx = threadIdx.x + blockIdx.x * blockDim.x;
    float value = 0;

    while(idx < %(IMAGE_W)s * %(IMAGE_W)s){
        float sum = 0;
        int dx = idx / %(IMAGE_W)s;
        int dy = idx %(MOD)s (%(IMAGE_W)s);
#pragma unroll
        for(int i = -%(KERNEL_R)s; i <= %(KERNEL_R)s; i++){
#pragma unroll
            for(int j = -%(KERNEL_R)s; j <= %(KERNEL_R)s; j++){
                if ((dx + i < 0) || (dx + i >= %(IMAGE_W)s)){
                    value = 0;
                }
                else if ((dy + j < 0) || (dy + j >= %(IMAGE_W)s)){
                    value = 0;
                }
                else{
                    value = pic[(dx + i) * %(IMAGE_W)s + (dy + j)] *
                            kernel[%(KERNEL_L)s * (%(KERNEL_R)s + i) + %(KERNEL_R)s + j];
                }
                sum += value;
            }
        }
        out[idx] = sum;
        idx += blockDim.x * gridDim.x;
    }
}
""" % {
        'KERNEL_R': KERNEL_R, 'KERNEL_L': KERNEL_L, 'IMAGE_W': IMAGE_W, 'MOD': '%'
    }

{% endhighlight python %}

这里面有些变量我直接用字符串替换过去了，还是比较方便的，但是写起来的时候很别扭。

函数的输出依然要把数据从显存里面拷出来：

{% highlight python %}
outgpu = np.zeros_like(out_s)
drv.memcpy_dtoh(outgpu, out_gpu)
{% endhighlight python %}

最后，虽然 CUDA 自己提供了垃圾收集机制，但是还是自己 free 一下放心：

{% highlight python %}
out_gpu.free()
{% endhighlight python %}

## 3. 时间获取

要计算 CUDA 函数运行的时间，CUDA 自带了函数，大致这样用：

{% highlight python %}
start = drv.Event()
end = drv.Event()
start.record()
niv_conv(out_gpu, kernel_gpu, pic_gpu,
         block=block, grid=grid)
end.record()
end.synchronize()
secs = start.time_till(end)
{% endhighlight python %}

获取的时间单位是毫秒。

## 4. Code with bugs

I write some demos [here](https://github.com/firiceguo/my-pycuda), some of them may still have bugs.
